---
title: "p8105_hw2_yw3995"
author: "Yuxuan Wang"
date: "2023-10-04"
output: github_document
---

# Problem 0

```{r setup, include = FALSE}
library(tidyverse)
library(readxl)
```

# Problem 1

## Clean the data in pols-month.csv

```{r, message = FALSE}
pols_df = 
  read_csv(file = "./data/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(mon, into = c("year", "month", "day")) %>% 
  mutate(month = month.abb[as.numeric(month)]) %>% 
  mutate(president = ifelse(prez_dem == 0, "dem", "gop")) %>% 
  select(-prez_dem, -prez_gop, -day)

pols_df
```

## Clean the data in snp.csv

```{r, message = FALSE}
snp_df = 
  read_csv(file = "./data/snp.csv") %>% 
  janitor::clean_names() %>% 
  mutate(date = as.Date(date, format = "%m/%d/%y"),
         date = as.Date(ifelse(date > Sys.Date(),
                               format(date, "19%y-%m-%d"),
                               format(date)))) %>% 
  separate(date, into = c("year", "month", "day")) %>% 
  mutate(month = month.abb[as.numeric(month)]) %>% 
  select(-day) %>% 
  arrange(year, month) %>% 
  relocate(year, month)

snp_df
```

## Clean the data in unemployment.csv

```{r, message = FALSE}
unemployment_df = 
  read_csv(file = "./data/unemployment.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "percentage") %>% 
  mutate(month = str_to_title(month))

unemployment_df$year = as.character(unemployment_df$year)

unemployment_df
```

## Merging

```{r, message = FALSE}
polssnp_df = 
  merge(pols_df, snp_df, by = c("year", "month")) %>% 
  arrange(year, month)
```

```{r, message = FALSE}
merge_df = 
  merge(polssnp_df, unemployment_df, by = c("year", "month")) %>% 
  arrange(year) %>% 
  relocate(year)
```

* Conclusion

  * The dataset **"pols_df"** is about the date and the number of national politicians who are democratic or republican from **Jan. 1947** to **Jun. 2015**, which contains **`r names(pols_df)`** and the size of the dataset is **`r nrow (pols_df)`** rows * **`r ncol(pols_df)`** cols;
  *  The dataset **"snp_df"** is about the date and values of Standard & Poorâ€™s stock market index (S&P) from **Jan. 1950** to **Jul. 2015**, which contains **`r names(snp_df)`** and the size of the dataset is **`r nrow (snp_df)`** rows * **`r ncol(snp_df)`** cols;
  *  The dataset **"unemployment_df"** is about the date and the percentage of unemployment from **Jan. 1948** to **Dec. 2015**, which contains **`r names(unemployment_df)`** and the size of the dataset is **`r nrow (unemployment_df)`** rows * **`r ncol(unemployment_df)`** cols;
  * The dataset **"merge_df"** is the sum of the above three files, containing the number of national politicians, closing values of the S&P stock index, and the percentage of unemployed from **Jan. 1950** to **Jun. 2015**, which contains **`r names(merge_df)`** and the size of the dataset is **`r nrow (merge_df)`** rows * **`r ncol(merge_df)`** cols.
  
# Problem 2

## Clean the Mr. Trash Wheel sheet

```{r, message = FALSE}
Mr_trash = 
  readxl::read_excel("./data/202309 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", range = "A2:N586" ) %>% 
  janitor::clean_names()

Mr_trash =  
  mutate(Mr_trash,
  homes_powered = (weight_tons*500)/30
) %>% 
  mutate(name = "Mr_trash")

Mr_trash
```

## Clean the Professor Trash Wheel sheet

```{r, message = FALSE}
Professor_trash = 
   readxl::read_excel("./data/202309 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", range = "A2:M108") %>% 
  janitor::clean_names()
  
Professor_trash =  
  mutate(Professor_trash, 
    homes_powered = (weight_tons*500)/30
) %>% 
  mutate(name = "Professor_trash")

Professor_trash$year = as.character(Professor_trash$year)

Professor_trash
```

## Clean the Gwynnda Trash Wheel sheet

```{r, message = FALSE}
Gwynnda_trash = 
  readxl::read_excel("./data/202309 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", range = "A2:L157") %>% 
  janitor::clean_names() 

Gwynnda_trash =
  mutate(Gwynnda_trash,
  homes_powered = (weight_tons*500)/30
) %>% 
  mutate(name = "Gwynnda_trash")

Gwynnda_trash$year = as.character(Gwynnda_trash$year)

Gwynnda_trash
```

## Merging

```{r, message = FALSE}
trash_wheel = 
  bind_rows(Mr_trash, Professor_trash, Gwynnda_trash) %>% 
  janitor::clean_names() %>% 
  select(name, everything()) 

trash_wheel
```

## The Gwynnda dataset in July of 2021

```{r, message = FALSE}
total_ciga = filter(Gwynnda_trash, year == "2021", month == "July") 
```

* Conclusion

  * The data **"Mr_trash"** is about the Mr. Trash Wheel sheet from **May. 2014** to **Jul. 2022**, which contains **`r names(Mr_trash)`** and the number of the observations is **`r nrow (Mr_trash)`**;
  * The data **"Professor_trash"** is about the Professor Trash Wheel sheet from **Jan. 2017** to **Jul. 2022**, which contains **`r names(Professor_trash)`** and the number of the observations is **`r nrow (Professor_trash)`**;
  * The data **"Gwynnda_trash"** is about the Gwynnda Trash Wheel sheet from **Jul. 2021** to **Jul. 2022**, which contains **`r names(Gwynnda_trash)`** and the number of the observations is **`r nrow (Gwynnda_trash)`**;
  * The data **"trash_wheel"** is the sum of the above three files, which contains **`r names(trash_wheel)`** and the number of the observations is **`r nrow (trash_wheel)`**  from **May. 2014** to **Jul. 2022**.
  
* Questions

  * What was the total weight of trash collected by Professor Trash Wheel? 
    * **`r sum (Professor_trash $ weight_tons)`**.
  * What was the total number of cigarette butts collected by Gwynnda in July of 2021?
    * **`r sum (total_ciga $ cigarette_butts)`**.
    
# Problem 3

## Clean the dataset of baseline demographics

```{r, message = FALSE}
MCI_baseline = 
  read_csv(file = "./data/MCI_baseline.csv", skip = 1) %>% 
  janitor::clean_names() %>% 
  mutate(sex = ifelse(sex == 1, "male", "female")) %>% 
  mutate(apoe4 = ifelse(apoe4 == 1, "carrier", "non_carrier"))
```

```{r, message = FALSE}
MCI = filter(MCI_baseline, !(age_at_onset < 0))
```

* Discussion

  * The important steps in the import process are using "read_csv" to import data, cleaning column names, changing the sex and APOE4 carrier status are appropriate encoded, and removing any participants who do not meet the stated inclusion criteria;
  * The dataset of "MCI" have **`r nrow(MCI)`** observations and **`r ncol(MCI)`** variables of participants with Mild Cognitive Impairment (MCI), which contains **`r names(MCI)`**.
  
## The women in MCI_baseline dataset
```{r, message = FALSE}
total_women = filter(MCI_baseline, sex == "female") 

total_women_carriers = filter(total_women, apoe4 == "carrier") 
```

* Questions

  * How many participants were recruited, and of these how many develop MCI? 
    * **`r nrow (MCI_baseline)`** participants were recruited and **`r nrow (MCI)`** participants develp MCI.
  * What is the average baseline age? 
    * **`r mean (MCI_baseline$current_age)`**.
  * What proportion of women in the study are APOE4 carriers?
    * **`r (nrow (total_women_carriers)/nrow (total_women))*100` %**.
  
## Clean the dataset of longitudinally observed biomarker values

```{r, message = FALSE}
mci_amyloid = 
  read_csv(file = "./data/mci_amyloid.csv", skip = 1) %>% 
  janitor::clean_names() 
  
mci_amyloid_new = 
  pivot_longer(mci_amyloid,
    baseline:time_8,
    names_to = "time",
    values_to = "value") %>% 
  rename(id = study_id) %>% 
  na.omit(mci_amyloid) %>% 
  filter(value != "Na")
```

* Discussion

  * The important steps in the import process are **using "read_csv" to import data, cleaning column names, using "pivot_longer" to tidy data, using "rename" to change study_id to id, and delete NA values**;
  * The dataset of "mci_amyloid" have **`r nrow(mci_amyloid_new)`** observations and **`r ncol(mci_amyloid_new)`** variables of information about id and 5 time intervals (in years) elapsed since the study baseline to the visit where biomarker Amyloid _ 42/40 ratio was measured, which contains **`r names(mci_amyloid_new)`**.

* Conclusion

  * I find that some participants appear in only the baseline or amyloid datasets. The amyloid datasets have **`r (nrow(mci_amyloid)-nrow(MCI_baseline))`** more participants than the baseline datasets. Baseline datasets have participants ids from 1 to 483, but amyloid datasets have non-consecutive participant ids from 1 to 495.

## Combining

```{r}
combine_df = 
  merge(MCI, mci_amyloid_new, by = c( "id"))
```

* Conclusion
  * The "combine_df" dataset have **`r nrow(combine_df)`** observations and **`r ncol(combine_df)`** variables of the basic informations of participants with Mild Cognitive Impairment (MCI), which contains **`r names(combine_df)`**.

## Export the result as a CSV

```{r}
write.csv(combine_df, "./results/combine_mci.csv")
```
